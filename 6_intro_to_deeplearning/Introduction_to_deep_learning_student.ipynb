{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjpGuyZbyFQT"
      },
      "source": [
        "<a href=\"https://githubtocolab.com/lucashervier/aibt/blob/main/6_intro_to_deeplearning/Introduction_to_deep_learning_student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>\n",
        "\n",
        "**All Rights Reserved**\n",
        "\n",
        "**Copyright (c) 2021 IRT Saint-Exupery**\n",
        "\n",
        "*Lab 2 contact : mehdi.zouitine@irt-saintexupery.com*\n",
        "\n",
        "# Labs 5: Introduction to Deep Learning\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "<b> Scope of this class: </b>\n",
        "5th hands'on practice of the AIBT mastere. In this session we will study and implement classical deep learning pipeline in Pytorch\n",
        "</div>\n",
        "\n",
        "The first part is inspired by an implementation of my colleague David bertoin from IRT Saint-Exup√©ry.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UMCLXRVxebDc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFEOuR5krD3u"
      },
      "source": [
        "## 0. Introduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBUpFiQhr3t8"
      },
      "source": [
        "The general concepts that you learned in machine learning models remain the same for deep learning.\n",
        "\n",
        "Just like in classical machine learning, the goal of a deep learning model is to learn a parameterized function $f_{\\theta}$ to solve a task. \n",
        "More precisely this set of parameters $\\theta$ is learned by minimizing an error function $L$ on a dataset $\\mathcal{D}$.\n",
        "\n",
        "Deep learning differs from classical machine learning because it does not require feature engineering.\n",
        "It is the network that will learn to extract the features useful to solve the task.\n",
        "\n",
        "In this session we will restrict ourselves to **supervised learning** tasks. : \n",
        "The data set is therefore of the following form $\\mathcal{D}:= (X,Y)$.\n",
        "\n",
        "And we try to minimize the following criteria:\n",
        "* For classfication task : \n",
        "$L(\\theta)=-\\mathbb{E}_{(X, Y) \\sim P}\\left(\\log \\left(f_{\\theta}(Y / X)\\right)\\right.$\n",
        "* For regression task : $L(\\theta)=\\mathbb{E}_{(X, Y) \\sim P}\\left(\\|Y-f_\\theta(X)\\|^{2}\\right)$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQm_ftHC0TNJ"
      },
      "source": [
        "## 1. Components of a deep learning pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVomRdKN0pFm"
      },
      "source": [
        "A supervised deep learning pipeline generally contains the following elements: \n",
        "* A **labelled dataset** $(X,Y)$\n",
        "* A **dataloader** (which allows to sample **batches** of data from the dataset)\n",
        "* A **neural network** $f_{\\theta}$\n",
        "* A **loss function** $L$\n",
        "* An **optimizer** that will allow the updating of the weights $\\theta$ by gradient descent on the loss function $L$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYeMJaxT39a4"
      },
      "source": [
        "##2. Data and data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "9dnqrhY-M14q",
        "outputId": "a5491fa7-c786-48d9-a602-6bc58d812c15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_boston\n",
        "df = load_boston();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRHr2FHJIHET"
      },
      "source": [
        "## 2. Neural network from scratch : Multilayer Perceptron "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KabA8k7DIgMD"
      },
      "source": [
        "To introduce neural networks we will work with the famous Boston dataset : The objective is to predict the **value of prices** of the house using the given **features**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "yVaroOXrOcqV"
      },
      "outputs": [],
      "source": [
        "data = np.asarray(df.data, dtype='float32')\n",
        "target = np.asarray(df.target, dtype='float32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z18A3WnvJ_qx"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 2.0 : </b>\n",
        "\n",
        "Separate your data into a training set and a validation set using `train_test_split`.\n",
        "\n",
        "\n",
        "</div>\n",
        "\n",
        "\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 2.1 : </b>\n",
        "\n",
        "Normalize the data and the target using `StandardScaler`.\n",
        "\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "OZ5H6IJtQMRs"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(data, target, test_size = 0.2, random_state=42)\n",
        "\n",
        "\n",
        "from sklearn import preprocessing\n",
        "# mean = 0 ; standard deviation = 1.0\n",
        "scaler = preprocessing.StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "y_train = scaler.fit_transform(y_train.reshape(-1,1))\n",
        "y_val = scaler.transform(y_val.reshape(-1,1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11Q62QFVKjhH"
      },
      "source": [
        "Neural networks are composed of layers.\n",
        "A layer is composed of two methods : \n",
        "* The **forward** method allows to apply the layer function to the inputs.\n",
        "* The **backward** method allows to compute the gradient of the weights of the layer compared to the gradient of the next layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "iJDA5A6AO079"
      },
      "outputs": [],
      "source": [
        "import abc\n",
        "class Layer(abc.ABC):\n",
        "    def __init__(self):\n",
        "        self.layer_type = 'abstract'\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        raise NotImplementedError\n",
        "    \n",
        "    def backward(self, grad):\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nuk9bc4BL36e"
      },
      "source": [
        "A linear layer is composed with a weights matrice $W$ and a bias vector $b$.\n",
        "The result of the application of the layer on $x$ is given by :  $$L_{W}(x) = Wx+b$$\n",
        "\n",
        "When the layer is created, the weights W and b are randomly initialized.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPgCTJ0aLvPe"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 2.2 : </b>\n",
        "Implement the `Linear` layer object.\n",
        "\n",
        "**Tip 1**: To apply the operation use the function `np.matmul function`.\n",
        "\n",
        "**Tip 2**: Initialize the weights between $[‚àí0.1,0.1]$ by using the function `np.random.uniform`\n",
        "\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "dJgmbA4i5Y5u",
        "outputId": "c5b17fc4-3b48-47e9-800f-dc7ef724d982",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.2877018 , -0.50032014,  1.0332369 , ...,  0.84534293,\n",
              "        -0.07433674,  1.753505  ],\n",
              "       [-0.33638445, -0.50032014, -0.4131595 , ...,  1.2047412 ,\n",
              "         0.43018377, -0.56147414],\n",
              "       [-0.40325332,  1.0132713 , -0.71521825, ..., -0.6371765 ,\n",
              "         0.06529749, -0.6515951 ],\n",
              "       ...,\n",
              "       [-0.40547013,  2.9593177 , -1.3033614 , ..., -0.59225154,\n",
              "         0.3790101 , -0.9106925 ],\n",
              "       [ 0.85189736, -0.50032014,  1.0332369 , ...,  0.84534293,\n",
              "        -2.694586  ,  1.5225704 ],\n",
              "       [-0.38135594, -0.50032014, -0.35216686, ...,  1.1598163 ,\n",
              "        -3.1215806 , -0.25731632]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "404*13"
      ],
      "metadata": {
        "id": "20VrKRhK8E-_",
        "outputId": "b8def3b4-61ad-4209-f453-02d420bb7f20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5252"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "pDxnIVgCOmHr"
      },
      "outputs": [],
      "source": [
        "class Linear(Layer):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super().__init__()\n",
        "        #weights is a tensor of dimension: (input_size x output_size) initialized...\n",
        "        #biais is a tensor of dimension: (output_size)\n",
        "        self.layer_type = 'linear'\n",
        "        self.params ={}\n",
        "        self.grads = {}\n",
        "        self.params[\"weights\"] = np.random.uniform(-0.1,0.1, size = (input_size,output_size))\n",
        "        self.params[\"bias\"] = np.random.uniform(-1,1, size = (output_size))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # outputs = inputs @ weights + biais\n",
        "        #we will store the inputs they will be used in the backward method\n",
        "        self.inputs = inputs\n",
        "        outputs = np.matmul(inputs, self.params[\"weights\"]) + self.params[\"bias\"]\n",
        "        return outputs\n",
        "    \n",
        "    def backward(self, grad):\n",
        "        # we need so sum gradients over the batch axis\n",
        "        self.grads[\"weights\"] = np.matmul(self.inputs.T, grad)\n",
        "        self.grads[\"bias\"] = np.sum(grad, axis=0)\n",
        "        return np.matmul(grad, self.params[\"weights\"].T)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiaaK3vBPdLY"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Test : </b>\n",
        "Make sure your implementation passes the test.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "qePKjjICO7SO"
      },
      "outputs": [],
      "source": [
        "input_size, output_size = 10, 5\n",
        "X = np.random.rand(input_size)\n",
        "grads = np.random.rand(10,5)\n",
        "test_linear_layer = Linear(input_size, output_size)\n",
        "assert test_linear_layer.forward(X).shape == (5,)\n",
        "assert test_linear_layer.backward(grads).shape == (10, 10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAP0Vr42QrYw"
      },
      "source": [
        "Activation functions are a very important element in deep learning architectures. These functions allow the introduction of non-linearity.\n",
        "\n",
        "An activation function is a differentiable function, the most famous is called `Relu` : $$Relu :\\mathbb{R}^d \\rightarrow \\mathbb{R}^d$$  $$Relu(x) = max(0,x)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUns1aW5TLYL"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 2.3 : </b>\n",
        "Implement the relu activation function and it's derivative.\n",
        "\n",
        "**Tip**: Use `np.max` and `np.where`.\n",
        "\n",
        "\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "z2YRhMQlO-se"
      },
      "outputs": [],
      "source": [
        "def relu(x):\n",
        "    return np.maximum(0,x)\n",
        "\n",
        "def relu_prime(x):\n",
        "    return np.where(x > 0, 1.0, 0.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-P9oPsjTfMF"
      },
      "source": [
        "From a computer point of view, an activation can be seen as a layer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpEPX6B-UIrj"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 2.4 : </b>\n",
        "Implement the `Activation``\n",
        " object.\n",
        "\n",
        "**Tip / Reminder**: if $y=f(x)$ and $x=f(z)$ then $\\frac{\\partial y}{\\partial z} = f'(x) * g'(z)$\n",
        "\n",
        "\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "1APtUpvvOrv2"
      },
      "outputs": [],
      "source": [
        "class Activation(Layer):\n",
        "    def __init__(self, f, f_prime):\n",
        "        super().__init__()\n",
        "        self.layer_type = 'activation'\n",
        "        self.f = f\n",
        "        self.f_prime = f_prime\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.intputs = inputs\n",
        "        return self.f(inputs)\n",
        "    \n",
        "    def backward(self, grad):\n",
        "        \"\"\" if y = f(x) and x = g(z)\n",
        "        then dy/dz = f'(x) * g'(z)\n",
        "        In our case g'(z) correspond to the incomming gradients\n",
        "        \"\"\"\n",
        "        return self.f_prime(self.inputs) * grad\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrpTk7yYVsVa"
      },
      "source": [
        "A neural network $f$ Is a succession of layers and activations : $$\\left.f(x)=f_{N}\\left(f_{N-1}\\left(\\ldots f_{1}\\left(x ; W_{1}, b_{1}\\right) ; W_{2}, b_{2}\\right) ; \\ldots\\right) ; W_{N}, b_{N}\\right)$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DslLgipeW2Fk"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 2.5 : </b>\n",
        "Implement the `Neuralnetwork` object.\n",
        "\n",
        "**Tip / Reminder**: The list operator `reversed` must be used.\n",
        "\n",
        "\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "U-lS5Zb_PavZ"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, layers):\n",
        "        self.layers = layers\n",
        "\n",
        "    def forward(self, inputs):\n",
        "      self.inputs = inputs\n",
        "      for layer in self.layers:\n",
        "        inputs = layer.forward(inputs)\n",
        "      return inputs\n",
        "\n",
        "    def backward(self, grad):\n",
        "      for layer in reversed(self.layers):\n",
        "        grad  = layer.backward(grad)\n",
        "      return grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztBG0_GaXO2Y"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 2.6 : </b>\n",
        "Implement a function `create_neural_net`.\n",
        "\n",
        "It must create a neural network consisting of 3 layers:\n",
        "* an input layer receiving a vector of dimension 13 and consisting of 40 neurons\n",
        "* a hidden layer of 40 neurons\n",
        "* an output layer consisting of a single neuron\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FEXtHQhKPBk9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "qKtNuiyzkadi"
      },
      "outputs": [],
      "source": [
        "def create_neural_net():\n",
        "  layers = [Linear(13,40), Activation(relu, relu_prime), Linear(40,1)]\n",
        "  net = NeuralNetwork(layers)\n",
        "  return net\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37spaNnZYYE-"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 2.7 : </b>\n",
        "* Instantiate a neural network\n",
        "* Make a precition on `X_val` using this neural network.\n",
        "* Compute the error using the MSE metric.\n",
        "* Plot the ground truth and the prediction\n",
        "\n",
        "**Tip**: Use `inverse_transform` and `mean_absolute_error` functions from sklearn.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "BRFd5GRfUNim",
        "outputId": "facfbea7-a026-42d7-94f8-7a914ecb9d86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0a1c815e50>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "net = create_neural_net()\n",
        "y_pred = net.forward(X_val)\n",
        "mse = mean_absolute_error(y_pred,y_val)\n",
        "\n",
        "   \n",
        "plt.figure(figsize=(20,5))\n",
        "plt.scatter(range(len(y_val)), scaler.inverse_transform(y_val), label='target')\n",
        "plt.scatter(range(len(y_val)), scaler.inverse_transform(y_pred), label='prediction')\n",
        "plt.title(\"Untrained neural network prediction\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEnkww35ZnoB"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 2.8 : </b>\n",
        "Comment the results : \n",
        "* Why is the model error so large ?\n",
        "* Why do all the predictions line up ?\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83MiNdsYaKD3"
      },
      "source": [
        "In order to train the network, we need a loss function to minimize.\n",
        "In the regression set up, the MSE do perfectly the job ! \n",
        "$$MSE(f(x),y) = \\sum_{i}^{n}\\frac{(f(x_i) - y_i)^2}{n}$$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCS0LtwHanaB"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 2.9 : </b>\n",
        "Implement the `MSE` function and its gradient.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "aqJD6O1gPo_W"
      },
      "outputs": [],
      "source": [
        "class MSE():\n",
        "\n",
        "    def loss(self, y_pred, y_true):\n",
        "        #returns a scalar\n",
        "        return np.square(y_pred - y_true).mean()\n",
        "    \n",
        "    def grad(self, y_pred, y_true):\n",
        "        #returns a tensor of gradients\n",
        "        return 2*(y_pred-y_true)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cowMy8WMA2R4"
      },
      "source": [
        "The loss function provides you with the error of your model. This error then allows you to update the weights of your model by gradient descent. The update of the weights is done with an optimizer. \n",
        "The optimizer goes through the weights and applies a gradient descent on these weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeV9denBB14K"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 2.10 : </b>\n",
        "Implement an optimizer.*texte en italique*\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "ZNsZM5EYPs2Z"
      },
      "outputs": [],
      "source": [
        "class SGD():\n",
        "    def __init__(self, lr=0.001):\n",
        "        self.lr = lr\n",
        "    \n",
        "    def step(self, net):\n",
        "        for layer in net.layers:\n",
        "            if layer.layer_type == 'linear':\n",
        "                for param, grad in zip(layer.params.values(), layer.grads.values()):\n",
        "                    param -= self.lr * grad\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12mxYTwqCEkN"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 2.11 : </b>\n",
        "Implement the fit function.\n",
        "This function must:\n",
        "\n",
        "* compute the predictions of the network on the learning batch\n",
        "* compute the loss\n",
        "* compute the gradient of the loss\n",
        "* retropagate the gradients\n",
        "* perform an optimization step\n",
        "* return the loss\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyrET-BhPwx7"
      },
      "outputs": [],
      "source": [
        "def fit(net, loss, optimizer, X, y):\n",
        "    y_pred = net.backward(X_val)\n",
        "    mse = MSE()\n",
        "    mse = mse.grad(y_pred,y_val)\n",
        "    gradients = net.backward(mse)\n",
        "\n",
        "    return prediction_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rL3ihLHCxLc"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 2.12 : </b>\n",
        "Train your neural network.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbkjsptZP1Lr"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "net = ...\n",
        "optimizer = ...\n",
        "loss = ...\n",
        "k=0\n",
        "for i, (x, y) in enumerate(zip(X_train, y_train)):\n",
        "    training_loss = ...\n",
        "    y_pred = ...\n",
        "    if i%66 == 0:\n",
        "      fig = plt.figure(figsize=(20,5));\n",
        "      plt.scatter(range(len(y_val)), scaler.inverse_transform(y_val), label='target');\n",
        "      plt.scatter(range(len(y_val)), scaler.inverse_transform(y_pred), label='prediction');\n",
        "      plt.title(f\"Prediction at iteration {i} // MSE = {mean_absolute_error(y_pred, y_val)}\")\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "print(mean_absolute_error(y_pred, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzUkGc1bC8Gr"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 2.13 : </b>\n",
        "Train your neural network over 10 epochs.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZfflUfMP71u"
      },
      "outputs": [],
      "source": [
        "net = create_neural_net()\n",
        "optimizer = SGD(lr=0.01)\n",
        "loss = MSE()\n",
        "for epoch in range(10):\n",
        "  for i, (x, y) in enumerate(zip(X_train, y_train)):\n",
        "      training_loss = fit(net, loss, optimizer, np.array([x]), np.array([y]))\n",
        "      y_pred = net.forward(X_val)\n",
        "  fig = plt.figure(figsize=(20,5));\n",
        "  plt.scatter(range(len(y_val)), scaler.inverse_transform(y_val), label='target');\n",
        "  plt.scatter(range(len(y_val)), scaler.inverse_transform(y_pred), label='prediction');\n",
        "  plt.title(f\"Prediction at epoch {epoch} // MSE = {mean_absolute_error(y_pred, y_val)}\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYAGWjbxDKcm"
      },
      "source": [
        "##3. Deep learning framework : Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEj3D4mMDxJ5"
      },
      "source": [
        "Pytorch is a deep learning framework allowing to automate many operations.\n",
        "It also provides a lot of tools to create and train deep learning models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpZXEKrmELBO"
      },
      "source": [
        "In deep learning, the type of data used is the **Tensor**.\n",
        "A tensor is an array of data that can contain vectors,images and much more ! \n",
        "\n",
        "\n",
        "You can instantiate a tensor using the `torch.tensor` method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRsbAR9_FWlV"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 3.0: </b>\n",
        "* Create a tensor `age_1` containing your age with type `long` and a tensor `size_1` containing your height in cm with type `float32`.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFns8IN0EXAC"
      },
      "outputs": [],
      "source": [
        "age_1 = ...\n",
        "size = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwteogJoHMft"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 3.1: </b>  \n",
        "Imagine your task is to predict the life expectancy of a person $y_i$ from a set of bioligical measure $(x_i^0,x_i^1,x_i^2,\\ldots,x_i^6)$.\n",
        "* Create three tensors `x_1`, `x_2` and `x_3` of biological data and form a data batch of size 3 `batch_x` with these three tensors.\n",
        "\n",
        "**Tip**: Use `torch.stack`.\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUzzyuz0HCDJ"
      },
      "outputs": [],
      "source": [
        "x1 = ...\n",
        "x2 = ...\n",
        "x3 = ...\n",
        "batch_x = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AM_nZ-sKpQ_"
      },
      "source": [
        "You can also check some attributes of your tensor.\n",
        "For example you can look at the shape of the tensor using the `shape` attribute, the gradient of a tensor using the `grad` attribute and the type using `dtype`.\n",
        "\n",
        "You can also see under which device your tensor is with the attribute `device`.\n",
        "Finally you can also put your data on gpu using the `torch.tensor.to` method.\n",
        "The possible devices are \"cpu\" and \"cuda\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWthyzPaLUNC"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 3.2: </b>  \n",
        "* Look at the device, gradient, type and shape of your tensors.\n",
        "* Change the device of your tensors to \"cuda\".\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJmG45YNN2E1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smItE_pONTbg"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 3.3: </b>  \n",
        "\n",
        "Transform the first three samples of `X_train` into a tensor and make a batch that you convert to the `torch.float32` type and pass to the cuda device.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VM3hBkjN3bb"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuhgORfyjHzW"
      },
      "source": [
        "To manage more easily the processing of your data, pytorch proposes a tool: the `Dataset` class.\n",
        "\n",
        "This class allows the creation of a data generator which will be very useful when training your model.\n",
        "\n",
        "This dataset allows to retrieve the data as a tensor.\n",
        "The dataset implements 2 methods : The `__get_item__` method which allows to access to a sample and the `__len__` method which returns the number of sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg3ELcPhOafQ"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 3.4: </b>  \n",
        "Implement a torch dataset allowing you to access the boston dataset.\n",
        "* The `__get_item__` method should return a dict containing the data and labels in tensor form.\n",
        "* The `__len__` method should return the number of samples.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rVZcW9brYUA"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPGHVFweq9Cq"
      },
      "outputs": [],
      "source": [
        "class TabularDataset(Dataset):\n",
        "  def __init__(self,X,y):\n",
        "    self.X = ...\n",
        "    self.y = ...\n",
        "  def __getitem__(self,idx): \n",
        "    return {\"data\": ...,\"label\": ...}\n",
        "\n",
        "  def __len__(self):\n",
        "    return ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv41rrnzO74f"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 3.5: </b>  \n",
        "Set up a dataset for the train set and one for the validation set\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsydoVVtmHFc"
      },
      "outputs": [],
      "source": [
        "train_dataset = ...\n",
        "val_dataset = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSmYeL0UpbjP"
      },
      "outputs": [],
      "source": [
        "print(f\"First sample (x,y) of the dataset : {train_dataset[0]} \\n\") # get_item method\n",
        "print(f\"There are {len(train_dataset)} samples in the dataset.\") # len method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVGhyRC3PxmS"
      },
      "source": [
        "Once the dataset is created, another class is used to wrap this dataset: The `Dataloader`.\n",
        "A dataloader allows to sample batches of dataset data and to parallelize the batch formation on several workers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd7tnsNgP6ct"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 3.6: </b>  \n",
        "Create a train dataloader and a validation dataloader that returns sample batches of size 16.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mqXOwOvnF78"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPXRTV7MnHX4"
      },
      "outputs": [],
      "source": [
        "batch_size = ...\n",
        "num_workers = ...\n",
        "train_dataloader = ...\n",
        "val_dataloader = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY0wScNwSCIs"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 3.7: </b>  \n",
        "* Inspect the first batch of your training loader.\n",
        "* Create a data variable and a label variable containing respectively, the data and the labels of the first batch\n",
        "\n",
        "**Tip**: To get the first element of the loader use: `next(iter(loader))`\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--fkRD-YpJPn"
      },
      "outputs": [],
      "source": [
        "first_batch = ...\n",
        "data = ...\n",
        "label = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_MTYYCHQv6B"
      },
      "source": [
        "In the previous part you created a neural network with linear layers.\n",
        "You had to implement the forward and backward method for each layer.\n",
        "Pytorch allows you to use well known layers like linear or convolutional layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knXVFlB7RdVu"
      },
      "source": [
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 3.8: </b>  \n",
        "Implement a neural network with a single linear layer using the pytorch framework.\n",
        "\n",
        "**Tip**: Use `nn.Linear` layer.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qr5pfgtOpHP5"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class MLPRegression(nn.Module): # All pytorch models must inherit the nn.Module\n",
        "  def __init__(self,in_features):\n",
        "     super(MLPRegression, self).__init__() # The constructor of the class calls the constructor of its parent class with the keyword \"super\".\n",
        "     self.layer1 = ...\n",
        "  def forward(self,x):\n",
        "    value = ...\n",
        "    return value\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGpdl3oCTr0i"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 3.9: </b>  \n",
        "Use your neural network to make a prediction on the first batch of data.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgqU0V5quJeI"
      },
      "outputs": [],
      "source": [
        "in_features = ...\n",
        "mlp_regression = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAuZA04_umDA"
      },
      "outputs": [],
      "source": [
        "preds = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqFLMFhbUv_U"
      },
      "source": [
        "Now we will move on to the most important part of the session: Training the model.\n",
        "Writing a **training loop** is not a simple thing at first.\n",
        "The following code implements a generic training loop that I advise you to keep for your future work in deep learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5WFQ2bZU2LB"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 3.10: </b>  \n",
        "* Explain the role of each argument of the function\n",
        "* Fill in the blank code\n",
        "* Comment on each line of the training loop (except the lines used for visualization).\n",
        "* Raise your hand to give me an oral report on this question \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ezk4DCJIu5C6"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "sns.set()\n",
        "def train_regressor(\n",
        "    model: nn.Module,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    train_loader: DataLoader,\n",
        "    valid_loader: DataLoader,\n",
        "    nb_epoch: int,\n",
        "    criterion: nn.Module,\n",
        "    batch_size:int=16,\n",
        "    device: torch.device = torch.device(\"cuda:0\"),\n",
        "    \n",
        "    verbose: bool=True,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Pytorch training loop\n",
        "    Args:\n",
        "        model (nn.Module): Pytorch classification model\n",
        "        optimizer (torch.optim.Optimizer): Optimizer for the model\n",
        "        train_loader (DataLoader): DataLoader for training fold\n",
        "        valid_loader (DataLoader): DataLoader for validation fold\n",
        "        nb_epoch (int): Number of epoch\n",
        "        criterion (nn.Module): Loss\n",
        "        device (torch.device): .Defaults to `torch.device(\"cuda:0\")`\n",
        "        verbose (bool): Verbose term\n",
        "    \"\"\"\n",
        "    loaders = {\"train\": train_loader, \"validation\": valid_loader}\n",
        "    model.to(device)\n",
        "    train_loss = []\n",
        "    val_loss = []\n",
        "    for epoch in range(1, nb_epoch + 1):\n",
        "        if verbose:\n",
        "          print(\"-\" * 80)\n",
        "        for phase in [\"train\", \"validation\"]:\n",
        "            if phase == \"train\":\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "            running_loss = 0.0\n",
        "            for sample in loaders[phase]:\n",
        "                data = ...\n",
        "                label = ...\n",
        "                optimizer.zero_grad()\n",
        "                data, label = data.to(device), label.to(device)\n",
        "                with torch.set_grad_enabled(phase == \"train\"):\n",
        "                    output = ...\n",
        "                    pred_label = ...\n",
        "                    loss = ...\n",
        "                    if phase == \"train\":\n",
        "                        ... # Compute the gradient\n",
        "                        ... # Make a gradient step\n",
        "                running_loss += loss.item()\n",
        "            epoch_loss = running_loss / (len(loaders[phase].dataset)/batch_size)\n",
        "            if phase == \"train\":\n",
        "              train_loss.append(epoch_loss)\n",
        "            else:\n",
        "              val_loss.append(epoch_loss)\n",
        "            if verbose:\n",
        "              print(\n",
        "                  f\" Epoch number: {epoch}, Phase: {phase}, Loss value: {epoch_loss:.4f}\"\n",
        "              )\n",
        "    fig,(axe1,axe2) = plt.subplots(2,figsize=(10,10))\n",
        "    fig.suptitle('Training and validation statistics')\n",
        "\n",
        "\n",
        "    y_pred = model(torch.from_numpy(X_val).to(device)).detach().cpu().numpy()\n",
        "    axe1.plot(np.arange(len(train_loss)),train_loss,label=\"train MSE\")\n",
        "    axe1.plot(np.arange(len(val_loss)),val_loss,label = \"val MSE\")\n",
        "    axe1.set_title(\"MSE loss\")\n",
        "    axe1.legend()\n",
        "    axe2.scatter(range(len(y_val)), scaler.inverse_transform(y_val), label='target');\n",
        "    axe2.scatter(range(len(y_val)), scaler.inverse_transform(y_pred), label='prediction');\n",
        "    axe2.set_title(f\"Prediction // MSE = {mean_absolute_error(y_pred, y_val)}\")\n",
        "    axe1.legend()\n",
        "    plt.show()\n",
        "    return train_loss,val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z9xAMu-VWPE"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 3.11: </b>  \n",
        "Instantiate the list of parameters necessary to launch the function and justify each of these parameters (Why use this loss, why use this optimizer, why set this learning rate, why use this architecture ...)  \n",
        "</div>\n",
        "\n",
        "**Tip**: Use `Adam` optimizer and have a look to https://pytorch.org/docs/stable/nn.html#loss-functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCf3UAFC7vC4"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Adam,SGD\n",
        "mlp_logistic = ...\n",
        "batch_size = ...\n",
        "num_workers = ...\n",
        "train_dataloader = ...\n",
        "val_dataloader = ...\n",
        "learning_rate = ...\n",
        "optimizer = ...\n",
        "criterion = ...\n",
        "device = ...\n",
        "nb_epochs = ...\n",
        "verbose = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHMguS8Avv6d"
      },
      "outputs": [],
      "source": [
        "train_loss,val_loss= ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_BPlmQEWV_Z"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 3.12: </b>  \n",
        "Comment the results on : \n",
        "* The loss function\n",
        "* The model error\n",
        "\n",
        "Can we do better and how?\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvW0uiJeXGnI"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 3.13: </b>  \n",
        "* Implement a new deeper architecture.\n",
        "* Set the necessary parameters for the training again and restart the procedure.\n",
        "* Comment on the new results obtained\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytbd-rXJAkrF"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class MLPDeep(nn.Module):\n",
        "  def __init__(self,in_features):\n",
        "     super(MLPDeep, self).__init__()\n",
        "     ...\n",
        "  def forward(self,x):\n",
        "    ...\n",
        "    return value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfESJeqOPdgJ"
      },
      "outputs": [],
      "source": [
        "mlp_deep = ...\n",
        "batch_size = ...\n",
        "num_workers = ...\n",
        "train_dataloader = ...\n",
        "val_dataloader = ...\n",
        "learning_rate = ...\n",
        "optimizer = ...\n",
        "criterion = ...\n",
        "device = ...\n",
        "nb_epochs = ...\n",
        "verbose = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lu68nVKMPCYZ"
      },
      "outputs": [],
      "source": [
        "train_loss,val_loss= ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-8jpkiDqGoI"
      },
      "source": [
        "## 4 : Pytorch model on image classification\n",
        "\n",
        "Now we will implement a pytorch model to train a classifier to predict someone's age from a picture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5opCAILo4At"
      },
      "source": [
        "Indian Movie Face database (IMFDB) is a large unconstrained face database consisting of 34512 images of 100 Indian actors collected from more than 100 videos. All the images are manually selected and cropped from the video frames resulting in a high degree of variability interms of scale, pose, expression, illumination, age, resolution, occlusion, and makeup. IMFDB is the first face database that provides a detailed annotation of every image in terms of age, pose, gender, expression and type of occlusion that may help other face related applications.\n",
        "\n",
        "The dataset provided a total of 19906 images.The attributes of data are as follows:\n",
        "\n",
        "* ID ‚Äì Unique ID of image\n",
        "* Class ‚Äì Age bin of person in image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sf6U6xKFdb-t"
      },
      "outputs": [],
      "source": [
        "! gdown --id 19Xb9r42B-Ajs13airFi5fghNcIjv4lDP\n",
        "! unzip archive.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OY_SuDe8hic1"
      },
      "outputs": [],
      "source": [
        "df_age = pd.read_csv(\"train.csv\")\n",
        "df_age.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82V59b3-s27q"
      },
      "outputs": [],
      "source": [
        "def to_numeric_class(x):\n",
        "  if x == \"YOUNG\":\n",
        "    return 0\n",
        "  elif x == \"MIDDLE\":\n",
        "    return 1\n",
        "  else:\n",
        "    return 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qm6LOgL-tUJU"
      },
      "outputs": [],
      "source": [
        "df_age[\"Class\"] = df_age[\"Class\"].apply(to_numeric_class).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuvkWjUpuSgn"
      },
      "outputs": [],
      "source": [
        "X_age_train, X_age_val, y_age_train, y_age_val = train_test_split(\n",
        "    df_age[\"ID\"], df_age[\"Class\"], test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vf4Xogqhu5qr"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NApvJ3xeDlPU"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 4.0.1: </b>  \n",
        "Fill in the few gaps and comment on each line of the loader.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uj__fkwVvPzM"
      },
      "outputs": [],
      "source": [
        "class AgeImageDataset(Dataset):\n",
        "  def __init__(self,X,y,transform=transforms.Compose([transforms.ToTensor(),transforms.Resize((32,32))])):\n",
        "    self.X = ...\n",
        "    self.y = ...\n",
        "    self.transform = ...\n",
        "  def __getitem__(self,idx):\n",
        "    img = self.transform(Image.open(f\"Train/{self.X.iloc[idx]}\"))\n",
        "    label = ... # Tip : use pandas.iloc method\n",
        "    return {\"data\":img,\"label\":label}\n",
        "  def __len__(self):\n",
        "    return self.X.shape[0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsA2YnvUwFxx"
      },
      "outputs": [],
      "source": [
        "age_train_dataset = AgeImageDataset(X=X_age_train,y=y_age_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gUap_xK-_i_"
      },
      "outputs": [],
      "source": [
        "len(age_train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sn3ydbfyYJ9"
      },
      "outputs": [],
      "source": [
        "def visualize_age_dataset(dataset,cols=4,rows=4):\n",
        "  labels_map = {\n",
        "      0: \"YOUNG\",\n",
        "      1: \"MIDDLE\",\n",
        "      2: \"OLD\",\n",
        "  }\n",
        "  figure = plt.figure(figsize=(10, 10))\n",
        "\n",
        "  for i in range(1, cols * rows + 1):\n",
        "      sample_idx = torch.randint(len(dataset), size=(1,)).item()\n",
        "      sample = dataset[sample_idx]\n",
        "      img = sample[\"data\"]\n",
        "      label = sample[\"label\"].item()\n",
        "      figure.add_subplot(rows, cols, i)\n",
        "      plt.title(labels_map[label])\n",
        "      plt.axis(\"off\")\n",
        "      plt.imshow(img.permute(1,2,0).cpu().numpy())\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hz9XUjK7wWlx"
      },
      "outputs": [],
      "source": [
        "visualize_age_dataset(age_train_dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2aJYe6bqcWj"
      },
      "source": [
        "\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 4.0.2: </b>  \n",
        "Implement a multi-layer perceptron (`Linear` layers with `ReLU` activations).\n",
        "\n",
        "**Tip**: Use a flatten layer (`nn.Flatten`)\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjjsXyg6nEXl"
      },
      "outputs": [],
      "source": [
        "class MLPImage(nn.Module):\n",
        "  def __init__(self,in_channels=3,n_class=3):\n",
        "    super(MLPImage, self).__init__()\n",
        "    self.flatten = ...\n",
        "    self.fc1 = ...\n",
        "    self.fc2 = ...\n",
        "    self.fc3 = ...\n",
        "    self.activation = ...\n",
        "    self.fc_logits = ...\n",
        "  def forward(self,x):\n",
        "    ...\n",
        "    return logits\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDHfk_yMsK_D"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 4.1: </b>  \n",
        "Adapt the training loop for this classification task. To do this: \n",
        "* Fill in the missing code\n",
        "* Comment on each line of the training loop (except the lines used for visualization).\n",
        "* Raise your hand to give me an oral report on this question \n",
        "\n",
        "**Tip**: Use `torch.argmax` function to get the index of the maximum of a vector.\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x05gB3EV6J64"
      },
      "outputs": [],
      "source": [
        "def train_age_classifier(\n",
        "    model: nn.Module,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    train_loader: DataLoader,\n",
        "    valid_loader: DataLoader,\n",
        "    nb_epoch: int,\n",
        "    criterion: nn.Module,\n",
        "    device: torch.device = torch.device(\"cuda:0\"),\n",
        "    verbose: bool=True,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Pytorch training loop\n",
        "    Args:\n",
        "        model (nn.Module): Pytorch classification model\n",
        "        optimizer (torch.optim.Optimizer): Optimizer for the model\n",
        "        train_loader (DataLoader): DataLoader for training fold\n",
        "        valid_loader (DataLoader): DataLoader for validation fold\n",
        "        nb_epoch (int): Number of epoch\n",
        "        criterion (nn.Module): Loss\n",
        "        device (torch.device): .Defaults to `torch.device(\"cuda:0\")`\n",
        "        verbose (bool): Verbose term\n",
        "    \"\"\"\n",
        "    loaders = {\"train\": train_loader, \"validation\": valid_loader}\n",
        "    model.to(device)\n",
        "    train_loss = []\n",
        "    val_loss = []\n",
        "    train_acc = []\n",
        "    val_acc = []\n",
        "    for epoch in range(1, nb_epoch + 1):\n",
        "        if verbose:\n",
        "          print(\"-\" * 80)\n",
        "        for phase in [\"train\", \"validation\"]:\n",
        "            if phase == \"train\":\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0.0\n",
        "            for sample in loaders[phase]:\n",
        "                data = ...\n",
        "                label = ...\n",
        "                optimizer.zero_grad()\n",
        "                data, label = data.to(device), label.to(device)\n",
        "                with torch.set_grad_enabled(phase == \"train\"):\n",
        "                    output = ...\n",
        "                    pred_label = ... # use torch.argmax\n",
        "                    loss = ...\n",
        "                    if phase == \"train\":\n",
        "                        ...\n",
        "                        ...\n",
        "                running_loss += loss.item()/data.size(0)\n",
        "                running_corrects += torch.sum(pred_label == label)\n",
        "            epoch_loss = running_loss / len(loaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.item() / (len(loaders[phase].dataset))\n",
        "            if phase == \"train\":\n",
        "              train_loss.append(epoch_loss)\n",
        "              train_acc.append(epoch_acc)\n",
        "            else:\n",
        "              val_loss.append(epoch_loss)\n",
        "              val_acc.append(epoch_acc)\n",
        "            if verbose:\n",
        "              print(\n",
        "                  f\" Epoch number: {epoch}, Phase: {phase}, Loss value: {epoch_loss:.4f}, Accuracy : {epoch_acc:.4f}\"\n",
        "              )\n",
        "    fig, axes = plt.subplots(1, 2,figsize=(10,5))\n",
        "    fig.suptitle('Training and validation statistics')\n",
        "\n",
        "    sns.lineplot(ax=axes[0], x=np.arange(len(train_loss)), y=train_loss)\n",
        "    sns.lineplot(ax=axes[0], x=np.arange(len(val_loss)), y=val_loss)\n",
        "    axes[0].legend(labels=[\"Train loss\",\"Val loss\"])\n",
        "\n",
        "    sns.lineplot(ax=axes[1], x=np.arange(len(train_acc)), y=train_acc)\n",
        "    sns.lineplot(ax=axes[1], x=np.arange(len(val_acc)), y=val_acc)\n",
        "    axes[1].legend(labels=[\"Train accuracy\",\"Val accuracy\"])\n",
        "    plt.show()\n",
        "    return train_loss,train_acc,val_loss,val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9EBJJ0HtVxE"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 4.2: </b>  \n",
        "Instantiate the list of parameters necessary to launch the function and justify each of these parameters (Why use this loss, why use this optimizer, why set this learning rate, why use this architecture ...)  \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QdCX5ojp827"
      },
      "outputs": [],
      "source": [
        "batch_size = ... \n",
        "num_workers = ... \n",
        "train_age_dataset = ... \n",
        "val_age_dataset = ... \n",
        "train_dataloader = ... \n",
        "val_dataloader = ...\n",
        "learning_rate = ...\n",
        "mlp_image = ... \n",
        "optimizer = ... \n",
        "criterion = ... \n",
        "device = ... \n",
        "nb_epochs = ... \n",
        "verbose = ... "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q47RPd5W1mCu"
      },
      "outputs": [],
      "source": [
        "train_loss,train_acc,val_loss,val_acc = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2tQm_YquWcy"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 4.3: </b>  \n",
        "Try to improve your model by increasing : \n",
        "* The number of parameters (more layers, more intermediate features)\n",
        "* Adding batch normalization and dropout (`nn.BatchNorm1D`and `nn.Dropout`) to prevent overfitting\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SykYEKzVv-5p"
      },
      "source": [
        "MLP's are not very efficient networks on images.\n",
        "**Convolutional** networks are much more adapted because they allow to exploit spatial information.\n",
        "Indeed, convolution networks have an **inductive bias** which is called the **locality bias**.\n",
        "\n",
        "The convolution operation is used to extract information from an image. For example the Sobel filter is an operator used in image processing for the detection of contours.\n",
        "The idea of convolutional networks is to **learn a set of filters to extract relevant information from the image**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IDR-1ZEyyBD"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 4.4: </b>  \n",
        "Using `nn.Conv2D`, implement a convolution layer with a square kernel of size 3 taking as input a tensor with 3 channels and returns a tensor with 16 channels. \n",
        "\n",
        "* Apply the convolution on the following image\n",
        "* Look at the output dimensions using the `torch.size` method.\n",
        "* Explain in detail this operation and the output dimensions.\n",
        "\n",
        "**Tip**: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n03kyj-Y1M9r"
      },
      "outputs": [],
      "source": [
        "image = age_train_dataset[0][\"data\"].unsqueeze(0)\n",
        "conv = \n",
        "res_conv = "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7W59q-i0Hw9"
      },
      "source": [
        "Another operation used in convolutional networks is **pooling** :\n",
        "\n",
        "Pooling is a feature commonly imbibed into Convolutional Neural Network (CNN) architectures. The main idea behind a pooling layer is to ‚Äúaccumulate‚Äù features from maps generated by convolving a filter over an image. Formally, its function is to progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the network. The most common form of pooling is max pooling.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvUVAdar1nSs"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 4.5: </b>  \n",
        "Using `nn.MaxPool2d`, implement a max pooling layer with a square kernel of size 2 and a stride of size 2 taking as input the result of the previous convolutional layer.\n",
        "\n",
        "* Look at the output dimensions using the `torch.size` method.\n",
        "* Explain in detail this operation and the output dimensions.\n",
        "\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFMAf9TJ2YXk"
      },
      "outputs": [],
      "source": [
        "pooling = ...\n",
        "res_pool = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw1Mi31_2_Lp"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 4.6: </b>  \n",
        "\n",
        "Implement the following convolutional network: \n",
        "* A convolution taking in input an image with 3 channels and outputting 16 channels with a kernel of size 3\n",
        "* A ReLu activation (`nn.ReLU`).\n",
        "* A 2D Batch Normalization (`nn.BatchNorm2d`).\n",
        "--------------------------------------------------------\n",
        "\n",
        "* A convolution taking in input an image with 16 channels and outputting 32 channels with a kernel of size 3\n",
        "* A MaxPooling2d layer with a kernel of size 2 and a stride of size 2\n",
        "* A ReLu activation (`nn.ReLU`).\n",
        "* A 2D Batch Normalization (`nn.BatchNorm2d`).\n",
        "--------------------------------------------------------\n",
        "* A convolution taking in input an image with 32 channels and outputting 64 channels with a kernel of size 3\n",
        "* A MaxPooling2d layer with a kernel of size 2 and a stride of size 2\n",
        "* A ReLu activation (`nn.ReLU`).\n",
        "* A 2D Batch Normalization (`nn.BatchNorm2d`).\n",
        "--------------------------------------------------------\n",
        "* A convolution taking in input an image with 64 channels and outputting 128 channels with a kernel of size 3\n",
        "* A MaxPooling2d layer with a kernel of size 2 and a stride of size 2\n",
        "* A ReLu activation (`nn.ReLU`).\n",
        "* A 2D Batch Normalization (`nn.BatchNorm2d`).\n",
        "--------------------------------------------------------\n",
        "* A flatten layer taking in input a 128 channels\n",
        "\n",
        "* A Linear layer taking in input 128*4 feature and outputting 3 logits.\n",
        "\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6lplPrnoH2V"
      },
      "outputs": [],
      "source": [
        "class SimpleConvModel(nn.Module):\n",
        "  def __init__(self,in_channels=3,n_class=3):\n",
        "    super(SimpleConvModel, self).__init__()\n",
        "    self.conv1 = ...  \n",
        "    self.conv2 = ...  \n",
        "    self.conv3 = ...  \n",
        "    self.conv4 = ...  \n",
        "    self.pool = ...  \n",
        "    self.activation = ...  \n",
        "    self.flatten = ...  \n",
        "    self.fc = ...  \n",
        "    self.bn1 = ...  \n",
        "    self.bn2 = ...  \n",
        "    self.bn3 = ...  \n",
        "\n",
        "  def forward(self,x):\n",
        "    ...\n",
        "    return logits\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebqUPl4S5b6-"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 4.7: </b>  \n",
        "Instantiate the list of parameters necessary to launch the function and justify each of these parameters (Why use this loss, why use this optimizer, why set this learning rate, why use this architecture ...)  \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZi3IfW67PYb"
      },
      "outputs": [],
      "source": [
        "batch_size = ... \n",
        "num_workers = ... \n",
        "train_age_dataset = ...\n",
        "val_age_dataset = ... \n",
        "train_dataloader = ... \n",
        "val_dataloader = ... \n",
        "learning_rate = ... \n",
        "simple_conv = ...\n",
        "optimizer = ... \n",
        "criterion = ... \n",
        "device = ... \n",
        "nb_epochs = ... \n",
        "verbose = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9N64iobypokb"
      },
      "outputs": [],
      "source": [
        "train_loss,train_acc,val_loss,val_acc =  ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVOJaSLd5lWB"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise 4.8: </b>  \n",
        "Comment on the results.\n",
        "How can we improve the performance of the model ? \n",
        "\n",
        "Try to improve your convolutional network.\n",
        "\n",
        "**Tip**: Use dropout to prevent overfitting `nn.Dropout2d(p=...)`\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5jNeVqG6ADw"
      },
      "source": [
        "An effective way to increase the performance of a model is to use a pre-trained model.\n",
        "The following codes allow to fine tune a model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvoT-RdF6icm"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "<b> Exercise BONUS: </b>  \n",
        "If you get to this step during the session, raise your hand and explain to me what you understand about this code.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaZoVKoodQB-"
      },
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "   if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_RPpDpKdqIZ"
      },
      "outputs": [],
      "source": [
        "use_pretrained = True\n",
        "feature_extract = False\n",
        "num_classes = 3\n",
        "model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "set_parameter_requires_grad(model_ft, feature_extract)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Sequential(nn.Dropout(p=0.7),nn.Linear(num_ftrs, 64),nn.Dropout(p=0.7),nn.Linear(64, num_classes))\n",
        "input_size = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWfwJtP18QCG"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "num_workers = 1\n",
        "train_age_dataset = AgeImageDataset(X=X_age_train,y=y_age_train)\n",
        "val_age_dataset = AgeImageDataset(X=X_age_val,y=y_age_val)\n",
        "train_dataloader = DataLoader(dataset=train_age_dataset,batch_size=batch_size,num_workers=num_workers)\n",
        "val_dataloader = DataLoader(dataset=val_age_dataset,batch_size=batch_size,num_workers=num_workers)\n",
        "learning_rate = 1e-4\n",
        "optimizer = Adam(params=model_ft.parameters(),lr=learning_rate,weight_decay=0.1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = \"cuda:0\"\n",
        "nb_epochs = 15\n",
        "verbose = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sR1qqSFI7HIQ"
      },
      "outputs": [],
      "source": [
        "train_loss,train_acc,val_loss,val_acc = train_age_classifier(model=model_ft,optimizer=optimizer,train_loader=train_dataloader,valid_loader=val_dataloader,\n",
        "                 nb_epoch=nb_epochs,criterion=criterion,device=device,verbose=verbose)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MF7e0BhH7d9O"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": " Introduction to deep learning_student.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}